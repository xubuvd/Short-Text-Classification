model               : TextRCNN
embedding           : random
dataset             : CR
word                : True
pad                 : 20
<models.TextRCNN.Config object at 0x7f95e290bfd0>
Loading data...
0it [00:00, ?it/s]2639it [00:00, 247745.38it/s]
Vocab size: 1143
0it [00:00, ?it/s]2639it [00:00, 162096.63it/s]
0it [00:00, ?it/s]566it [00:00, 164585.14it/s]
0it [00:00, ?it/s]565it [00:00, 165464.44it/s]
/home/pangwei/.conda/envs/vd/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
Time usage: 0:00:00
<bound method Module.parameters of Model(
  (embedding): Embedding(1143, 300, padding_idx=1142)
  (lstm): LSTM(300, 300, batch_first=True, dropout=0.2, bidirectional=True)
  (maxpool): MaxPool1d(kernel_size=20, stride=20, padding=0, dilation=1, ceil_mode=False)
  (fc): Sequential(
    (0): Dropout(p=0.2, inplace=False)
    (1): Linear(in_features=900, out_features=2, bias=True)
  )
)>
Epoch [1/20]
  0%|          | 0/82 [00:00<?, ?it/s]  5%|▍         | 4/82 [00:00<00:01, 39.58it/s] 17%|█▋        | 14/82 [00:00<00:00, 74.48it/s] 29%|██▉       | 24/82 [00:00<00:00, 84.52it/s] 43%|████▎     | 35/82 [00:00<00:00, 91.49it/s] 55%|█████▍    | 45/82 [00:00<00:00, 94.44it/s] 67%|██████▋   | 55/82 [00:00<00:00, 95.92it/s] 79%|███████▉  | 65/82 [00:00<00:00, 96.99it/s] 93%|█████████▎| 76/82 [00:00<00:00, 98.02it/s]83it [00:00, 87.02it/s]                        
Iter:      0,  Train Loss:   1.8,  Train Acc: 31.25%,  Val Loss:   3.0,  Val Acc: 61.48%,  Time: 0:00:00 *
Iter:     82,  Train Loss:  0.75,  Train Acc: 66.67%,  Val Loss:   0.5,  Val Acc: 74.20%,  Time: 0:00:01 *
Epoch [2/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 109.38it/s] 27%|██▋       | 22/82 [00:00<00:00, 103.77it/s] 40%|████      | 33/82 [00:00<00:00, 96.94it/s]  52%|█████▏    | 43/82 [00:00<00:00, 96.92it/s] 65%|██████▍   | 53/82 [00:00<00:00, 97.69it/s] 77%|███████▋  | 63/82 [00:00<00:00, 95.07it/s] 89%|████████▉ | 73/82 [00:00<00:00, 96.38it/s]83it [00:00, 84.93it/s]                        83it [00:00, 92.56it/s]
Iter:    164,  Train Loss:  0.32,  Train Acc: 84.38%,  Val Loss:   1.0,  Val Acc: 66.25%,  Time: 0:00:02 
Epoch [3/20]
  0%|          | 0/82 [00:00<?, ?it/s] 15%|█▍        | 12/82 [00:00<00:00, 117.47it/s] 29%|██▉       | 24/82 [00:00<00:00, 102.15it/s] 43%|████▎     | 35/82 [00:00<00:00, 100.06it/s] 56%|█████▌    | 46/82 [00:00<00:00, 99.32it/s]  68%|██████▊   | 56/82 [00:00<00:00, 96.26it/s] 80%|████████  | 66/82 [00:00<00:00, 96.62it/s] 93%|█████████▎| 76/82 [00:00<00:00, 97.06it/s]83it [00:00, 94.63it/s]                        
Iter:    246,  Train Loss:  0.52,  Train Acc: 71.88%,  Val Loss:  0.88,  Val Acc: 75.44%,  Time: 0:00:03 
Epoch [4/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 109.75it/s] 27%|██▋       | 22/82 [00:00<00:00, 101.14it/s] 40%|████      | 33/82 [00:00<00:00, 99.76it/s]  54%|█████▎    | 44/82 [00:00<00:00, 98.74it/s] 66%|██████▌   | 54/82 [00:00<00:00, 96.36it/s] 78%|███████▊  | 64/82 [00:00<00:00, 96.85it/s] 90%|█████████ | 74/82 [00:00<00:00, 96.35it/s]83it [00:00, 93.34it/s]                        
Iter:    328,  Train Loss:  0.78,  Train Acc: 71.88%,  Val Loss:   1.4,  Val Acc: 72.61%,  Time: 0:00:04 
Epoch [5/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 104.55it/s] 27%|██▋       | 22/82 [00:00<00:00, 99.96it/s]  40%|████      | 33/82 [00:00<00:00, 96.64it/s] 52%|█████▏    | 43/82 [00:00<00:00, 96.88it/s] 65%|██████▍   | 53/82 [00:00<00:00, 96.32it/s] 77%|███████▋  | 63/82 [00:00<00:00, 96.71it/s] 89%|████████▉ | 73/82 [00:00<00:00, 96.96it/s]83it [00:00, 89.68it/s]                        83it [00:00, 94.35it/s]
Iter:    410,  Train Loss:  0.46,  Train Acc: 81.25%,  Val Loss:  0.93,  Val Acc: 76.68%,  Time: 0:00:04 
Epoch [6/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 102.18it/s] 27%|██▋       | 22/82 [00:00<00:00, 97.49it/s]  39%|███▉      | 32/82 [00:00<00:00, 96.52it/s] 51%|█████     | 42/82 [00:00<00:00, 96.96it/s] 63%|██████▎   | 52/82 [00:00<00:00, 97.24it/s] 76%|███████▌  | 62/82 [00:00<00:00, 97.35it/s] 88%|████████▊ | 72/82 [00:00<00:00, 95.60it/s]100%|██████████| 82/82 [00:00<00:00, 89.30it/s]83it [00:00, 94.26it/s]                        
Iter:    492,  Train Loss: 0.0092,  Train Acc: 100.00%,  Val Loss:  0.95,  Val Acc: 78.45%,  Time: 0:00:05 
Epoch [7/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 101.12it/s] 27%|██▋       | 22/82 [00:00<00:00, 99.02it/s]  39%|███▉      | 32/82 [00:00<00:00, 97.79it/s] 51%|█████     | 42/82 [00:00<00:00, 96.37it/s] 63%|██████▎   | 52/82 [00:00<00:00, 96.70it/s] 76%|███████▌  | 62/82 [00:00<00:00, 96.91it/s] 88%|████████▊ | 72/82 [00:00<00:00, 97.04it/s]100%|██████████| 82/82 [00:00<00:00, 89.31it/s]83it [00:00, 94.45it/s]                        
Iter:    574,  Train Loss: 0.0028,  Train Acc: 100.00%,  Val Loss:  0.95,  Val Acc: 78.80%,  Time: 0:00:06 
Epoch [8/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 101.47it/s] 27%|██▋       | 22/82 [00:00<00:00, 98.90it/s]  39%|███▉      | 32/82 [00:00<00:00, 97.31it/s] 51%|█████     | 42/82 [00:00<00:00, 95.65it/s] 63%|██████▎   | 52/82 [00:00<00:00, 96.21it/s] 76%|███████▌  | 62/82 [00:00<00:00, 94.73it/s] 88%|████████▊ | 72/82 [00:00<00:00, 95.54it/s]100%|██████████| 82/82 [00:00<00:00, 90.07it/s]83it [00:00, 94.14it/s]                        
Iter:    656,  Train Loss:  0.02,  Train Acc: 100.00%,  Val Loss:   1.0,  Val Acc: 78.45%,  Time: 0:00:07 
Epoch [9/20]
  0%|          | 0/82 [00:00<?, ?it/s] 13%|█▎        | 11/82 [00:00<00:00, 101.36it/s] 27%|██▋       | 22/82 [00:00<00:00, 99.49it/s]  39%|███▉      | 32/82 [00:00<00:00, 99.05it/s] 51%|█████     | 42/82 [00:00<00:00, 98.73it/s] 63%|██████▎   | 52/82 [00:00<00:00, 98.41it/s] 76%|███████▌  | 62/82 [00:00<00:00, 97.30it/s] 88%|████████▊ | 72/82 [00:00<00:00, 97.25it/s]100%|██████████| 82/82 [00:00<00:00, 91.95it/s]83it [00:00, 95.88it/s]                        
Iter:    738,  Train Loss: 0.0004,  Train Acc: 100.00%,  Val Loss:  0.99,  Val Acc: 78.45%,  Time: 0:00:08 
Epoch [10/20]
  0%|          | 0/82 [00:00<?, ?it/s] 12%|█▏        | 10/82 [00:00<00:00, 98.68it/s] 24%|██▍       | 20/82 [00:00<00:00, 98.36it/s] 37%|███▋      | 30/82 [00:00<00:00, 98.29it/s] 49%|████▉     | 40/82 [00:00<00:00, 98.26it/s] 61%|██████    | 50/82 [00:00<00:00, 98.22it/s] 73%|███████▎  | 60/82 [00:00<00:00, 98.09it/s] 85%|████████▌ | 70/82 [00:00<00:00, 96.59it/s] 98%|█████████▊| 80/82 [00:00<00:00, 91.15it/s]83it [00:00, 95.37it/s]                        
Iter:    820,  Train Loss: 0.00059,  Train Acc: 100.00%,  Val Loss:   1.0,  Val Acc: 78.27%,  Time: 0:00:09 
Epoch [11/20]
  0%|          | 0/82 [00:00<?, ?it/s] 12%|█▏        | 10/82 [00:00<00:00, 97.89it/s] 24%|██▍       | 20/82 [00:00<00:00, 95.27it/s] 37%|███▋      | 30/82 [00:00<00:00, 96.71it/s] 49%|████▉     | 40/82 [00:00<00:00, 97.04it/s] 61%|██████    | 50/82 [00:00<00:00, 93.78it/s] 73%|███████▎  | 60/82 [00:00<00:00, 95.14it/s] 85%|████████▌ | 70/82 [00:00<00:00, 95.93it/s] 98%|█████████▊| 80/82 [00:00<00:00, 90.40it/s]83it [00:00, 93.98it/s]                        
Iter:    902,  Train Loss: 0.0018,  Train Acc: 100.00%,  Val Loss:   1.0,  Val Acc: 78.09%,  Time: 0:00:10 
Epoch [12/20]
  0%|          | 0/82 [00:00<?, ?it/s]  0%|          | 0/82 [00:00<?, ?it/s]
No optimization for a long time in last 11 epochs, auto-stopping...
Test Loss:  0.46,  Test Acc: 78.23%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           1     0.7792    0.5742    0.6612       209
           2     0.7835    0.9045    0.8396       356

    accuracy                         0.7823       565
   macro avg     0.7813    0.7393    0.7504       565
weighted avg     0.7819    0.7823    0.7736       565

Confusion Matrix...
[[120  89]
 [ 34 322]]
Time usage: 0:00:00
